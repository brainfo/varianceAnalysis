{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/data/hong/courses/varianceAnalysis/')\n",
    "# with open(\"data/ADA_uniprot.json\", \"r\") as file:\n",
    "#     uniprot = file.read()\n",
    "#     ins = re.findall(r'(p\\.[A-Z]{1}[a-z]+\\d+_[A-Z]{1}[a-z]+\\d+ins[A-Z]{1}[a-z]+)\"',uniprot)\n",
    "#     deletions = re.findall(r'(p\\.[A-Z]{1}[a-z]+\\d+del)',uniprot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block is to generate random p. insertions and deletions  \n",
    "and is not necessary for the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one2all ={'A': ('A', 'ALA', 'alanine'),\n",
    "    'R': ('R', 'ARG', 'arginine'),\n",
    "    'N': ('N', 'ASN', 'asparagine'),\n",
    "    'D': ('D', 'ASP', 'aspartic acid'),\n",
    "    'C': ('C', 'CYS', 'cysteine'),\n",
    "    'Q': ('Q', 'GLN', 'glutamine'),\n",
    "    'E': ('E', 'GLU', 'glutamic acid'),\n",
    "    'G': ('G', 'GLY', 'glycine'),\n",
    "    'H': ('H', 'HIS', 'histidine'),\n",
    "    'I': ('I', 'ILE', 'isoleucine'),\n",
    "    'L': ('L', 'LEU', 'leucine'),\n",
    "    'K': ('K', 'LYS', 'lysine'),\n",
    "    'M': ('M', 'MET', 'methionine'),\n",
    "    'F': ('F', 'PHE', 'phenylalanine'),\n",
    "    'P': ('P', 'PRO', 'proline'),\n",
    "    'S': ('S', 'SER', 'serine'),\n",
    "    'T': ('T', 'THR', 'threonine'),\n",
    "    'W': ('W', 'TRP', 'tryptophan'),\n",
    "    'Y': ('Y', 'TYR', 'tyrosine'),\n",
    "    'V': ('V', 'VAL', 'valine'),\n",
    "    'X': ('X', 'GLX', 'glutaminx'),\n",
    "    'Z': ('Z', 'GLI', 'glycine'),\n",
    "    'J': ('J', 'NLE', 'norleucine'),\n",
    "    'U': ('U', 'CYC', 'cysteinc')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in fa\n",
    "with open(\"data/ADA.fa\", \"r\") as file:\n",
    "    fa = file.read()\n",
    "    fa = fa.split('\\n')\n",
    "    fa = [i for i in fa if i != '']\n",
    "    fa = fa[1:]\n",
    "    fa = ''.join(fa)\n",
    "    fa = list(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As I didn't find a good reference for insertion or deletoin frequency, \n",
    "## and the question of this assignment has nothing to do with the frequency\n",
    "## but just the functional predictoin \"when\" it happens\n",
    "## So these indels are created by random\n",
    "## I will create 9 random insertions and 9 random deletions\n",
    "import random\n",
    "random.seed(404)\n",
    "def mk_ins(fa, random_ins, ins):\n",
    "    for i in random_ins:\n",
    "        aa1 = one2all[fa[i]][1]\n",
    "        aa2 = one2all[fa[i+1]][1]\n",
    "        aai = random.choice(list(one2all.keys()))\n",
    "        insi = f'p.{aa1}{i}_{aa2}{i+1}ins{aai}'\n",
    "        ins.append(insi)\n",
    "    return ins\n",
    "\n",
    "## generate 18 random integers in the range of length of fa\n",
    "\n",
    "random_ints = random.sample(range(0, len(fa)), 18)\n",
    "random_ins = random_ints[:9]\n",
    "random_del = random_ints[9:]\n",
    "ins_generate = mk_ins(fa, random_ins, ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_del(fa, random_del, deletions):\n",
    "    for i in random_del:\n",
    "        aa1 = one2all[fa[i]][1]\n",
    "        deli = f'p.{aa1}{i}del'\n",
    "        deletions.append(deli)\n",
    "    return deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "deletions_generate = mk_del(fa, random_del, deletions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write out ins_generate and deletions_generate\n",
    "## to tsv files\n",
    "df_ins = pd.DataFrame(ins_generate, columns=['ins'])\n",
    "df_del = pd.DataFrame(deletions_generate, columns=['del'])\n",
    "df_ins.to_csv('data/ins.tsv', sep='\\t', index=False)\n",
    "df_del.to_csv('data/del.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from here comes what's used in answering the exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyhgvs as hgvs\n",
    "from pyhgvs.utils import read_transcripts\n",
    "from pyfaidx import Fasta\n",
    "\n",
    "# Read genome sequence using pyfaidx.\n",
    "genome = Fasta('/mnt/data/hong/tools/annovar/humandb/hg19_seq/hg19.fa')\n",
    "\n",
    "# Read RefSeq transcripts into a python dict.\n",
    "with open('/mnt/data/hong/tools/annovar/humandb/hg19_refGene.txt') as infile:\n",
    "    transcripts = read_transcripts(infile)\n",
    "\n",
    "# Provide a callback for fetching a transcript by its name.\n",
    "def get_transcript(name):\n",
    "    return transcripts.get(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">NM_000022   Comment: this sequence (leftmost exon at chr20:43248162) is generated by ANNOVAR on Thu Feb 22 09:03:55 2024, based on regions specified in humandb/hg19_refGene.txt and sequence files stored at humandb/hg19_seq.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get codon frequency\n",
    "def index_containing_substring(the_list, substring):\n",
    "    for i, s in enumerate(the_list):\n",
    "        if substring in s:\n",
    "              return i\n",
    "    return -1\n",
    "with open('/mnt/data/hong/tools/annovar/humandb/hg19_refGeneMrna.fa') as fi:\n",
    "    line_list = fi.readlines()\n",
    "    line_idx = index_containing_substring(line_list, 'NM_000022')\n",
    "    print(line_list[line_idx])\n",
    "    line_start ='a'\n",
    "    coding_seq = ''\n",
    "    while line_start != '>':\n",
    "        coding_seq = coding_seq+ line_list[line_idx+1].strip()\n",
    "        line_idx += 1\n",
    "        line_start = line_list[line_idx+1][0]\n",
    "\n",
    "## need to get the correct transcript sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_transcript = len(coding_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "codon = [coding_seq[i:i+3] for i in range(0,len(coding_seq), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## consider that I might fall short of insertions or deletions\n",
    "## as some of them might map to other genes close to the gene of interest\n",
    "## or in the UTR region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HGVS name into genomic coordinates and alleles.\n",
    "## create HGVS names\n",
    "## 'NG_007385.1':c.1234_1235insACGT\n",
    "## https://databases.lovd.nl/shared/refseq/ADA_NM_000022.2_codingDNA.html\n",
    "ng = 'NM_000022'\n",
    "import random\n",
    "random.seed(404)\n",
    "def mk_cins():\n",
    "    i = 1\n",
    "    while True:\n",
    "        start = random.sample(range(1, len_transcript//3-3), 1)[0]*3-1\n",
    "        end = start +1\n",
    "        ins_seq = random.sample(codon, 1)[0]\n",
    "        ins_hgvs = f'{ng}:c.{start}_{end}ins{ins_seq}'\n",
    "        yield ins_hgvs, i\n",
    "        i += 1\n",
    "chroms, offsets, refs, alts = [], [], [], []\n",
    "with open('data/indel.vcf', 'a') as out_vcf:\n",
    "    out_vcf.write('#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\n')\n",
    "    for ins_names, num in mk_cins():\n",
    "        if num > 15:\n",
    "            break\n",
    "        chrom, offset, ref, alt = hgvs.parse_hgvs_name(ins_names, genome, get_transcript=get_transcript, lazy=True)\n",
    "        out_vcf.write(f'{chrom}\\t{offset}\\t{ins_names}\\t{ref}\\t{alt}\\t.\\tPASS\\t.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NM_000492.3:c.1438_1440delGGT\n",
    "def mk_cdel():\n",
    "    i = 1\n",
    "    while True:\n",
    "        th = random.sample(range(1, len_transcript//3-3), 1)[0]\n",
    "        start = th*3-1\n",
    "        end = start +2\n",
    "        del_seq = codon[th]\n",
    "        del_hgvs = f'{ng}:c.{start}_{end}del{del_seq}'\n",
    "        yield del_hgvs, i\n",
    "        i += 1\n",
    "chroms, offsets, refs, alts = [], [], [], []\n",
    "with open('data/indel.vcf', 'a') as out_vcf:\n",
    "    for del_names, num in mk_cdel():\n",
    "        if num > 15:\n",
    "            break\n",
    "        chrom, offset, ref, alt = hgvs.parse_hgvs_name(del_names, genome, get_transcript=get_transcript, lazy=True)\n",
    "        out_vcf.write(f'{chrom}\\t{offset}\\t{del_names}\\t{ref}\\t{alt}\\t.\\tPASS\\t.\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
